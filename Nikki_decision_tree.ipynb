{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, decision_tree.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprepare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prep_titanic, prep_telco, split_data\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01macquire\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m new_titanic_data, new_telco_data\n",
      "File \u001b[0;32m~/codeup-data-science/classification-exercises/acquire.py:78\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     76\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m---> 78\u001b[0m train, val_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43miris_df\u001b[49m, train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     79\u001b[0m                                   random_state \u001b[38;5;241m=\u001b[39m seed,\n\u001b[1;32m     80\u001b[0m                                   stratify \u001b[38;5;241m=\u001b[39m iris_df\u001b[38;5;241m.\u001b[39mspecies)\n\u001b[1;32m     81\u001b[0m val, test \u001b[38;5;241m=\u001b[39m train_test_split(val_test, train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     82\u001b[0m                             random_state \u001b[38;5;241m=\u001b[39m seed,\n\u001b[1;32m     83\u001b[0m                             stratify \u001b[38;5;241m=\u001b[39m val_test\u001b[38;5;241m.\u001b[39mspecies)\n\u001b[1;32m     84\u001b[0m train\u001b[38;5;241m.\u001b[39mspecies\u001b[38;5;241m.\u001b[39mvalue_counts(normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'iris_df' is not defined"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from prepare import prep_titanic, prep_telco, split_data\n",
    "from acquire import new_titanic_data, new_telco_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire data\n",
    "titanic = prep_titanic(new_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validate, split data\n",
    "train, validate, test = split_data(titanic, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts for target value: survived\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know what our X and y are, let's be explicit about defining them\n",
    "X_train = train.drop(columns='survived')\n",
    "y_train = train.survived\n",
    "\n",
    "X_val = validate.drop(columns='survived')\n",
    "y_val = validate.survived\n",
    "\n",
    "X_test = test.drop(columns='survived')\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (train == 0)\n",
    "\n",
    "print(f\"Baseline accuracy: {matches_baseline_prediction.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['sex'] = X_train.sex.map({'male': 1, 'female': 0})\n",
    "X_train['embark_town'] = X_train.embark_town.map({'Southampton': 1, 'Queenstown': 0})\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "tree1 = tree1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model\n",
    "# Evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree1, feature_names=X_train.columns.tolist(), class_names=['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have our model clf, let's get those metrics from our informational output\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf = confusion_matrix(y_train, y_predictions)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_train, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "labels\n",
    "\n",
    "pd.DataFrame(conf, index=[str(label) + ' actual'for label in labels], columns=[str(label) + ' predict'for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = conf.ravel()\n",
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = (TP + TN + FP + FN)\n",
    "\n",
    "accuracy = (TP + TN) / all\n",
    "\n",
    "TPR = recall = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "TNR = TN / (FP + TN)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "precision =  TP / (TP + FP)\n",
    "f1 =  2 * ((precision * recall) / ( precision + recall))\n",
    "\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {TPR}\")\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {FPR}\")\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {TNR}\")\n",
    "print(f\"False Negative Rate/Miss Rate: {FNR}\\n\")\n",
    "print(f\"Precision/PPV: {precision}\")\n",
    "print(f\"F1 Score: {f1}\\n\")\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth = 1\n",
    "tree2 = DecisionTreeClassifier(max_depth=1, random_state= 42)\n",
    "tree2.fit(X_train, y_train)\n",
    "tree2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from previous tree1 max depth = 3\n",
    "tree1.fit(X_train, y_train)\n",
    "tree1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "6. Which model performs better on your in-sample data?\n",
    "\n",
    "* Model with max depth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "7. Which model performs best on your out-of-sample data, the validate set?\n",
    "\n",
    "* very close, but model with depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up validate set\n",
    "X_val['sex'] = X_val.sex.map({'male': 1, 'female': 0})\n",
    "X_val['embark_town'] = X_val.embark_town.map({'Southampton': 1, 'Queenstown': 0})\n",
    "X_val.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth = 1 \n",
    "tree = DecisionTreeClassifier(max_depth=1, random_state= 42)\n",
    "out_tree = tree.fit(X_train, y_train)\n",
    "out_tree.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max depth = 3\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "out_tree = tree.fit(X_train, y_train)\n",
    "out_tree.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "1. Work through these same exercises using the Telco dataset.\n",
    "\n",
    "2. Experiment with this model on other datasets with a higher number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire data\n",
    "telco = prep_telco(new_telco_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, validate, split data\n",
    "train, validate, test = split_data(telco, 'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['customer_id', 'gender', 'senior_citizen', 'partner', 'dependents', 'phone_service', 'multiple_lines', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'paperless_billing', 'contract_type', 'internet_service_type', 'payment_type'])\n",
    "\n",
    "train['total_charges'] = train['total_charges'].str.strip()\n",
    "train = train[train.total_charges != '']\n",
    "train['total_charges'] = train.total_charges.astype(float)\n",
    "\n",
    "train['churn'] = train.churn.map({'Yes': 1, 'No': 0})\n",
    "train['churn'] = train.churn.astype(int)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns='churn')\n",
    "y_train = train.churn\n",
    "\n",
    "X_val = validate.drop(columns='churn')\n",
    "y_val = validate.churn\n",
    "\n",
    "X_test = test.drop(columns='churn')\n",
    "y_test = test.churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "churn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "churn_tree1 = churn_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize\n",
    "plt.figure(figsize=(13, 7))\n",
    "plot_tree(churn_tree, feature_names=X_train.columns.tolist(), \n",
    "class_names = np.array(churn_tree.classes_).astype('str').tolist(), rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = churn_tree.score(X_train, y_train)\n",
    "print(f'Model 1 accuracy: {accuracy:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
